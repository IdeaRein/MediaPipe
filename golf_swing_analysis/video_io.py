import cv2
import mediapipe as mp
import numpy as np
import os
from swing_features import extract_summary_features


# =========================================================
# ğŸŸ¡ ãƒœãƒ¼ãƒ«é™æ­¢æ¤œå‡ºï¼ˆè¿½åŠ é–¢æ•°ï¼‰
# =========================================================
def detect_ball_stationary_frame(ball_positions: np.ndarray, threshold=1.0, stable_count=5):
    """
    ãƒœãƒ¼ãƒ«ã®åº§æ¨™å¤‰åŒ–ãŒä¸€å®šä»¥ä¸‹ã®çŠ¶æ…‹ãŒé€£ç¶šã—ãŸã‚‰ã€Œé™æ­¢ã€ã¨åˆ¤å®šã—ã€
    ãã®æœ€å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’è¿”ã™ã€‚
    """
    if len(ball_positions) < 2:
        return None

    # NaNé™¤å»ï¼ˆæ¬ æãŒæ··ã˜ã£ã¦ã„ã‚‹ã¨å·®åˆ†è¨ˆç®—ãŒå£Šã‚Œã‚‹ãŸã‚ï¼‰
    valid = ~np.isnan(ball_positions[:, 0])
    ball_positions = ball_positions[valid]

    if len(ball_positions) < 2:
        return None

    distances = np.linalg.norm(np.diff(ball_positions, axis=0), axis=1)
    stable_frames = np.where(distances < threshold)[0]

    for i in range(len(stable_frames) - stable_count):
        if stable_frames[i + stable_count - 1] - stable_frames[i] == stable_count - 1:
            return int(stable_frames[i + stable_count - 1])

    return None


# =========================================================
# ğŸ¯ ãƒœãƒ¼ãƒ«è¿½è·¡ï¼ˆOpenCVç‰ˆï¼‰è»½é‡ãƒˆãƒ©ãƒƒã‚«ãƒ¼
# =========================================================
def track_ball_positions(video_path: str, resize_scale=0.5, color_thresh=(180, 30, 30), debug=False):
    """
    ç™½ã„ãƒœãƒ¼ãƒ«é ˜åŸŸã‚’ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«è¿½è·¡ã—ã€(x, y)åº§æ¨™ã‚’è¿”ã™ã€‚
    ç…§æ˜æ¡ä»¶ã«ã‚ˆã£ã¦ã¯color_threshã‚’èª¿æ•´ã™ã‚‹ã€‚
    """
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise RuntimeError(f"å‹•ç”»ãŒé–‹ã‘ã¾ã›ã‚“: {video_path}")

    positions = []
    kernel = np.ones((3, 3), np.uint8)

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        h, w, _ = frame.shape
        small = cv2.resize(frame, (int(w * resize_scale), int(h * resize_scale)))
        hsv = cv2.cvtColor(small, cv2.COLOR_BGR2HSV)

        # âœ… ä¿®æ­£1: color_threshã®ä½¿ã„æ–¹ï¼ˆH, S, Vã”ã¨ã®ã—ãã„å€¤ï¼‰
        lower_white = np.array([0, 0, 255 - color_thresh[2]])  # 255 - Væˆåˆ†
        upper_white = np.array([180, color_thresh[1], 255])

        mask = cv2.inRange(hsv, lower_white, upper_white)

        # âœ… ä¿®æ­£2: ãƒã‚¤ã‚ºé™¤å»ï¼ˆèª¤æ¤œå‡ºé˜²æ­¢ï¼‰
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        mask = cv2.GaussianBlur(mask, (5, 5), 0)

        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if len(contours) > 0:
            c = max(contours, key=cv2.contourArea)
            (x, y), r = cv2.minEnclosingCircle(c)
            positions.append((x, y))
            if debug:
                cv2.circle(small, (int(x), int(y)), int(r), (0, 255, 0), 2)
        else:
            positions.append((np.nan, np.nan))

        if debug:
            cv2.imshow("ball_tracking", small)
            if cv2.waitKey(1) & 0xFF == ord("q"):
                break

    cap.release()
    cv2.destroyAllWindows()
    return np.array(positions)


# =========================================================
# ğŸ§© ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æŠ½å‡ºï¼‹ãƒ•ãƒ¬ãƒ¼ãƒ ä¿å­˜ï¼ˆæ—¢å­˜æ‹¡å¼µï¼‰
# =========================================================
def extract_landmarks_from_video(video_path, resize_scale=0.5, max_frames=1000, output_dir="outputs"):
    """
    å‹•ç”»ã‹ã‚‰MediaPipe Poseã§éª¨æ ¼ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æŠ½å‡ºã—ã€
    ãƒˆãƒƒãƒ—ãƒ»ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãƒ»æœ€åˆãƒ»æœ€å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¿å­˜ã€‚
    ã•ã‚‰ã«ãƒœãƒ¼ãƒ«åº§æ¨™ã‚‚è¿½è·¡ã—ã¦é™æ­¢ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¤œå‡ºã€‚
    """
    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(static_image_mode=False, model_complexity=1)
    os.makedirs(output_dir, exist_ok=True)

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise RuntimeError(f"å‹•ç”»ãŒé–‹ã‘ã¾ã›ã‚“: {video_path}")

    # âœ… ä¿®æ­£3: FPSãŒå–å¾—ã§ããªã„å‹•ç”»å¯¾ç­–
    fps = cap.get(cv2.CAP_PROP_FPS)
    if not fps or fps <= 1:
        fps = 30

    original_frames = []
    landmarks_all = []
    frame_indices = []
    frame_count = 0

    while True:
        ret, frame = cap.read()
        if not ret or frame_count >= max_frames:
            break

        original_frames.append(frame.copy())
        h, w, _ = frame.shape
        small_frame = cv2.resize(frame, (int(w * resize_scale), int(h * resize_scale)))
        frame_rgb = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)

        result = pose.process(frame_rgb)
        if result.pose_landmarks:
            frame_landmarks = np.array(
                [[lm.x, lm.y, lm.z, lm.visibility] for lm in result.pose_landmarks.landmark]
            )
            landmarks_all.append(frame_landmarks)
            frame_indices.append(frame_count)

        frame_count += 1

    cap.release()
    pose.close()

    if len(landmarks_all) == 0:
        raise RuntimeError("ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

    landmarks_all = np.array(landmarks_all)
    np.save(os.path.join(output_dir, "landmarks.npy"), landmarks_all)
    print(f"âœ… æŠ½å‡ºãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(original_frames)}ï¼ˆæ¤œå‡ºæˆåŠŸ: {len(landmarks_all)}ï¼‰")

    # ---- ãƒˆãƒƒãƒ—ãƒ»ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆæ¤œå‡º ----
    features = extract_summary_features(landmarks_all, fps=int(fps))
    top_idx, impact_idx = features["top_frame"], features["impact_frame"]
    top_real_idx = frame_indices[top_idx] if top_idx < len(frame_indices) else None
    impact_real_idx = frame_indices[impact_idx] if impact_idx < len(frame_indices) else None

    # ---- ãƒœãƒ¼ãƒ«è¿½è·¡ã¨é™æ­¢åˆ¤å®š ----
    print("ğŸ¯ ãƒœãƒ¼ãƒ«è¿½è·¡ã‚’é–‹å§‹ã—ã¾ã™...")
    ball_positions = track_ball_positions(video_path, resize_scale=resize_scale)
    np.save(os.path.join(output_dir, "ball_positions.npy"), ball_positions)

    stationary_frame = detect_ball_stationary_frame(ball_positions)
    if stationary_frame is not None:
        print(f"âšª ãƒœãƒ¼ãƒ«é™æ­¢ãƒ•ãƒ¬ãƒ¼ãƒ æ¤œå‡º: {stationary_frame}")
    else:
        print("âšª ãƒœãƒ¼ãƒ«é™æ­¢ãƒ•ãƒ¬ãƒ¼ãƒ ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

    # ---- ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒã®ä¿å­˜ ----
    # âœ… ä¿®æ­£4: Noneãƒã‚§ãƒƒã‚¯ + ç¯„å›²å¤–ã‚¢ã‚¯ã‚»ã‚¹é˜²æ­¢
    if len(original_frames) > 0:
        cv2.imwrite(os.path.join(output_dir, "first_frame.jpg"), original_frames[0])
        cv2.imwrite(os.path.join(output_dir, "last_frame.jpg"), original_frames[-1])
    if top_real_idx is not None and 0 <= top_real_idx < len(original_frames):
        cv2.imwrite(os.path.join(output_dir, "top_frame.jpg"), original_frames[top_real_idx])
    if impact_real_idx is not None and 0 <= impact_real_idx < len(original_frames):
        cv2.imwrite(os.path.join(output_dir, "impact_frame.jpg"), original_frames[impact_real_idx])

    print(f"âœ… ãƒˆãƒƒãƒ—ãƒ»ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆï¼‹æœ€åˆãƒ»æœ€å¾Œãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¿å­˜ã—ã¾ã—ãŸ ({output_dir})")

    return landmarks_all, ball_positions, stationary_frame
