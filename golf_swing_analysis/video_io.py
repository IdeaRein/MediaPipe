import cv2
import mediapipe as mp
import numpy as np
import os
from swing_features import extract_summary_features


# =========================================================
# ğŸŸ¡ ãƒœãƒ¼ãƒ«é™æ­¢æ¤œå‡º
# =========================================================
def detect_ball_stationary_frame(ball_positions: np.ndarray, threshold=1.0, stable_count=5):
    """ãƒœãƒ¼ãƒ«ã®åº§æ¨™å¤‰åŒ–ãŒä¸€å®šä»¥ä¸‹ã®çŠ¶æ…‹ãŒé€£ç¶šã—ãŸã‚‰ã€Œé™æ­¢ã€ã¨åˆ¤å®šã€‚"""
    if len(ball_positions) < 2:
        return None

    valid = ~np.isnan(ball_positions[:, 0])
    ball_positions = ball_positions[valid]
    if len(ball_positions) < 2:
        return None

    distances = np.linalg.norm(np.diff(ball_positions, axis=0), axis=1)
    stable_frames = np.where(distances < threshold)[0]

    for i in range(len(stable_frames) - stable_count):
        if stable_frames[i + stable_count - 1] - stable_frames[i] == stable_count - 1:
            return int(stable_frames[i + stable_count - 1])
    return None


# =========================================================
# ğŸ¯ ãƒœãƒ¼ãƒ«è¿½è·¡ï¼ˆOpenCVç‰ˆï¼‰
# =========================================================
def track_ball_positions(video_path: str, resize_scale=0.5, color_thresh=(180, 30, 30), debug=False):
    """ç™½ã„ãƒœãƒ¼ãƒ«é ˜åŸŸã‚’ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«è¿½è·¡ã—ã€(x, y)åº§æ¨™ã‚’è¿”ã™ã€‚"""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise RuntimeError(f"å‹•ç”»ãŒé–‹ã‘ã¾ã›ã‚“: {video_path}")

    positions = []
    kernel = np.ones((3, 3), np.uint8)

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        h, w, _ = frame.shape
        small = cv2.resize(frame, (int(w * resize_scale), int(h * resize_scale)))
        hsv = cv2.cvtColor(small, cv2.COLOR_BGR2HSV)

        lower_white = np.array([0, 0, 255 - color_thresh[2]])
        upper_white = np.array([180, color_thresh[1], 255])
        mask = cv2.inRange(hsv, lower_white, upper_white)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        mask = cv2.GaussianBlur(mask, (5, 5), 0)

        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if len(contours) > 0:
            c = max(contours, key=cv2.contourArea)
            (x, y), r = cv2.minEnclosingCircle(c)
            positions.append((x, y))
        else:
            positions.append((np.nan, np.nan))

        if debug:
            cv2.imshow("ball_tracking", small)
            if cv2.waitKey(1) & 0xFF == ord("q"):
                break

    cap.release()
    cv2.destroyAllWindows()
    return np.array(positions)


# =========================================================
# ğŸ§© ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æŠ½å‡ºï¼‹ãƒ•ãƒ¬ãƒ¼ãƒ ä¿å­˜ï¼ˆã‚ºãƒ¬å®Œå…¨ä¿®æ­£ç‰ˆï¼‰
# =========================================================
def extract_landmarks_from_video(video_path, resize_scale=0.5, max_frames=1000, output_dir="outputs"):
    """
    å‹•ç”»ã‹ã‚‰MediaPipe Poseã§éª¨æ ¼ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æŠ½å‡ºã—ã€
    ãƒˆãƒƒãƒ—ãƒ»ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãƒ»æœ€åˆãƒ»æœ€å¾Œãƒ»å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ­£ç¢ºã«ä¿å­˜ã€‚
    """
    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(static_image_mode=False, model_complexity=1)
    os.makedirs(output_dir, exist_ok=True)

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise RuntimeError(f"å‹•ç”»ãŒé–‹ã‘ã¾ã›ã‚“: {video_path}")

    fps = cap.get(cv2.CAP_PROP_FPS)
    if not fps or fps <= 1:
        fps = 30

    frame_count = 0
    landmarks_all = []
    all_frames = []       # å…¨ãƒ•ãƒ¬ãƒ¼ãƒ 
    detected_frames = []  # ãƒãƒ¼ã‚ºæ¤œå‡ºã«æˆåŠŸã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆã“ã‚Œã‚’ä¿å­˜ã«ä½¿ã†ï¼‰

    while True:
        ret, frame = cap.read()
        if not ret or frame_count >= max_frames:
            break

        all_frames.append(frame.copy())  # å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ä¿å­˜
        h, w, _ = frame.shape
        small_frame = cv2.resize(frame, (int(w * resize_scale), int(h * resize_scale)))
        frame_rgb = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)

        result = pose.process(frame_rgb)
        if result.pose_landmarks:
            frame_landmarks = np.array(
                [[lm.x, lm.y, lm.z, lm.visibility] for lm in result.pose_landmarks.landmark]
            )
            landmarks_all.append(frame_landmarks)
            detected_frames.append(frame.copy())  # â† æ¤œå‡ºæˆåŠŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¿å­˜ã«ä½¿ã†

        frame_count += 1

    cap.release()
    pose.close()

    if not landmarks_all:
        raise RuntimeError("ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

    landmarks_all = np.array(landmarks_all)
    np.save(os.path.join(output_dir, "landmarks.npy"), landmarks_all)
    print(f"âœ… æŠ½å‡ºãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(all_frames)}ï¼ˆæ¤œå‡ºæˆåŠŸ: {len(landmarks_all)}ï¼‰")

    # ===== ãƒˆãƒƒãƒ—ãƒ»ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆæ¤œå‡º =====
    features = extract_summary_features(landmarks_all, fps=int(fps))
    top_idx, impact_idx = features["top_frame"], features["impact_frame"]
    print(f"ğŸ” æ¤œå‡ºçµæœ â†’ ãƒˆãƒƒãƒ—:{top_idx}, ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ:{impact_idx}")

    # ===== å…¨ãƒ•ãƒ¬ãƒ¼ãƒ å‡ºåŠ› =====
    for i, f in enumerate(all_frames):
        cv2.imwrite(os.path.join(output_dir, f"frame_{i:03d}.jpg"), f)
    print(f"ğŸ–¼ï¸ å…¨ {len(all_frames)} ãƒ•ãƒ¬ãƒ¼ãƒ ä¿å­˜å®Œäº† ({output_dir})")

    # ===== ä»£è¡¨ãƒ•ãƒ¬ãƒ¼ãƒ ä¿å­˜ï¼ˆå®Œå…¨ä¸€è‡´ç‰ˆï¼‰ =====
    # ãƒˆãƒƒãƒ—ã¨ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã¯æ¤œå‡ºã«æˆåŠŸã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ç›´æ¥ä¿å­˜ï¼ˆã‚ºãƒ¬ãªã—ï¼‰
    if 0 <= top_idx < len(detected_frames):
        cv2.imwrite(os.path.join(output_dir, "top_frame.jpg"), detected_frames[top_idx])
    else:
        print(f"âš ï¸ ãƒˆãƒƒãƒ—ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå· {top_idx} ãŒç¯„å›²å¤–ã§ã™")

    if 0 <= impact_idx < len(detected_frames):
        cv2.imwrite(os.path.join(output_dir, "impact_frame.jpg"), detected_frames[impact_idx])
    else:
        print(f"âš ï¸ ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå· {impact_idx} ãŒç¯„å›²å¤–ã§ã™")

    # æœ€åˆãƒ»æœ€å¾Œã¯å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰
    if all_frames:
        cv2.imwrite(os.path.join(output_dir, "first_frame.jpg"), all_frames[0])
        cv2.imwrite(os.path.join(output_dir, "last_frame.jpg"), all_frames[-1])

    print("âœ… ãƒˆãƒƒãƒ—ãƒ»ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãƒ»æœ€åˆãƒ»æœ€å¾Œãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¿å­˜å®Œäº†ï¼")

    # ===== ãƒœãƒ¼ãƒ«è¿½è·¡ =====
    print("ğŸ¯ ãƒœãƒ¼ãƒ«è¿½è·¡ã‚’é–‹å§‹ã—ã¾ã™...")
    ball_positions = track_ball_positions(video_path, resize_scale=resize_scale)
    stationary_frame = detect_ball_stationary_frame(ball_positions)
    np.save(os.path.join(output_dir, "ball_positions.npy"), ball_positions)

    if stationary_frame is not None:
        print(f"âšª ãƒœãƒ¼ãƒ«é™æ­¢ãƒ•ãƒ¬ãƒ¼ãƒ æ¤œå‡º: {stationary_frame}")
    else:
        print("âšª ãƒœãƒ¼ãƒ«é™æ­¢ãƒ•ãƒ¬ãƒ¼ãƒ ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

    return landmarks_all, ball_positions, stationary_frame
