import os
import numpy as np
from utils import extract_audio, detect_audio_impact
from swing_features import refine_impact_by_motion
from video_io import detect_ball_stationary_frame


def detect_hybrid_impact(video_path: str, fps: int = 30, output_dir: str = "outputs"):
    """
    éŸ³ï¼‹éª¨æ ¼ï¼‹ãƒœãƒ¼ãƒ«é™æ­¢ã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã§ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚’æ¤œå‡º
    """
    os.makedirs(output_dir, exist_ok=True)

    # === Step1: éŸ³å£°ã‚’æŠ½å‡ºã—ã¦ã‚ªãƒ³ã‚»ãƒƒãƒˆã‚’æ¤œå‡º ===
    audio_path = extract_audio(video_path)
    audio_frame = detect_audio_impact(audio_path, fps)
    search_window = (max(0, (audio_frame or 0) - 5), (audio_frame or 0) + 5)

    # === Step2: ãƒœãƒ¼ãƒ«é™æ­¢ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ¤œå‡º ===
    ball_path = os.path.join(output_dir, "ball_positions.npy")
    if not os.path.exists(ball_path):
        raise FileNotFoundError(f"ãƒœãƒ¼ãƒ«åº§æ¨™ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {ball_path}\nå…ˆã« video_io.extract_landmarks_from_video() ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    ball_positions = np.load(ball_path)

    stationary_frame = detect_ball_stationary_frame(ball_positions, threshold=1.0, stable_count=5)

    # === Step3: éª¨æ ¼ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³è§£æ ===
    lm_path = os.path.join(output_dir, "landmarks.npy")
    if not os.path.exists(lm_path):
        raise FileNotFoundError(f"ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {lm_path}\nå…ˆã« video_io.extract_landmarks_from_video() ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    landmarks = np.load(lm_path)

    # âœ… ä¿®æ­£1: éŸ³ãŒNoneã®å ´åˆã‚‚è€ƒæ…®ã—ã¦ fallback
    if audio_frame is None and stationary_frame is None:
        rough_idx = 0
    elif audio_frame is None:
        rough_idx = stationary_frame
    elif stationary_frame is None:
        rough_idx = audio_frame
    else:
        # éŸ³ã¨ãƒœãƒ¼ãƒ«é™æ­¢ãŒä¸¡æ–¹ã‚ã‚Œã°ã€Œå…ˆã«èµ·ã“ã‚‹æ–¹ã€ã‚’å„ªå…ˆ
        rough_idx = min(audio_frame, stationary_frame)

    refined_idx = refine_impact_by_motion(landmarks, fps, rough_idx, window=3)

    # === Step4: çµ±åˆåˆ¤å®š ===
    if stationary_frame is not None:
        impact_frame = min(refined_idx, stationary_frame)
        confidence = 0.95
    elif audio_frame is not None:
        impact_frame = refined_idx
        confidence = 0.85
    else:
        impact_frame = refined_idx
        confidence = 0.7

    # === Step5: ãƒ­ã‚°å‡ºåŠ› ===
    print("========== ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆæ¤œå‡ºçµæœ ==========")
    print(f"ğŸ§ éŸ³å£°æ¨å®šãƒ•ãƒ¬ãƒ¼ãƒ : {audio_frame}")
    print(f"âšª ãƒœãƒ¼ãƒ«é™æ­¢ãƒ•ãƒ¬ãƒ¼ãƒ : {stationary_frame}")
    print(f"ğŸŒï¸ ç²¾å¯†è£œæ­£å¾Œãƒ•ãƒ¬ãƒ¼ãƒ : {refined_idx}")
    print(f"âœ… æœ€çµ‚ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ : {impact_frame}")
    print(f"ğŸ“Š ä¿¡é ¼åº¦: {confidence:.2f}")
    print("=======================================")

    return {
        "impact_frame": int(impact_frame),
        "audio_frame": int(audio_frame) if audio_frame is not None else None,
        "stationary_frame": int(stationary_frame) if stationary_frame is not None else None,
        "confidence": confidence,
    }
