import numpy as np
import cv2
import os
from utils import line_angle, angle_3pt, smooth_series


# =========================================================
# ğŸ§© ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ­£è¦åŒ–
# =========================================================
def normalize_landmarks(landmarks: np.ndarray) -> np.ndarray:
    out = landmarks.copy()
    T = landmarks.shape[0]
    for t in range(T):
        L = out[t]
        left_sh, right_sh = L[11][:2], L[12][:2]
        left_hip, right_hip = L[23][:2], L[24][:2]
        shoulder_w = np.linalg.norm(np.array(right_sh) - np.array(left_sh)) + 1e-6
        pelvis = (np.array(left_hip) + np.array(right_hip)) / 2
        out[t, :, 0] = (out[t, :, 0] - pelvis[0]) / shoulder_w
        out[t, :, 1] = (out[t, :, 1] - pelvis[1]) / shoulder_w
    return out


# =========================================================
# ğŸŒï¸ è¿½åŠ : ãƒœãƒ¼ãƒ«æ¶ˆå¤±æ¤œå‡º (OpenCV)
# =========================================================
def detect_ball_disappearance(video_path: str) -> int | None:
    """
    OpenCVã§ãƒœãƒ¼ãƒ«ãŒæœ€å¾Œã«è¦‹ãˆã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¤œå‡ºã€‚
    æ˜ã‚‹ã„å††å½¢é ˜åŸŸï¼ˆç™½ã„ãƒœãƒ¼ãƒ«ï¼‰ãŒè¦‹ã¤ã‹ã£ãŸæœ€å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’è¿”ã™ã€‚
    """
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âš ï¸ å‹•ç”»ãŒé–‹ã‘ã¾ã›ã‚“: {video_path}")
        return None

    frame_idx = 0
    last_visible = None

    while True:
        ret, frame = cap.read()
        if not ret:
            break
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        # ãƒœãƒ¼ãƒ«ï¼ˆæ˜ã‚‹ãå°ã•ãªå††ï¼‰ã‚’æ¤œå‡º
        circles = cv2.HoughCircles(
            gray, cv2.HOUGH_GRADIENT, dp=1.2, minDist=30,
            param1=80, param2=18, minRadius=2, maxRadius=8
        )
        if circles is not None:
            last_visible = frame_idx
        frame_idx += 1

    cap.release()
    return last_visible


# =========================================================
# ğŸ§© æ”¹è‰¯ç‰ˆã‚­ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆæ¤œå‡ºï¼ˆãƒœãƒ¼ãƒ«è£œæ­£å¯¾å¿œï¼‰
# =========================================================
def detect_keyframes(landmarks: np.ndarray, fps: int = 30, video_path: str = None, output_dir: str = "outputs") -> dict:
    """
    æ”¹è‰¯ç‰ˆï¼ˆãƒˆãƒƒãƒ—æ¤œå‡ºã‚¿ã‚¤ãƒŸãƒ³ã‚°è£œæ­£ï¼‹ç”»åƒä¿å­˜ã¤ãï¼‰:
      - ãƒˆãƒƒãƒ—: æ‰‹ã®é«˜ã•(y)ãŒä¸Šæ˜‡â†’ä¸‹é™ã«è»¢ã˜ã‚‹â€œæœ€é«˜ç‚¹â€ã®ç›´å‰
      - ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ: æ‰‹é€Ÿåº¦ãŒæœ€å¤§ã«ãªã‚‹ç¬é–“
      - æ¤œå‡ºç›´å¾Œã«å¯¾è±¡ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒã‚’ä¿å­˜ï¼ˆvideo_pathå¿…é ˆï¼‰
    """
    T = landmarks.shape[0]
    if T < 5:
        return {"top": 0, "impact": max(0, T - 1)}

    left_wr, right_wr = landmarks[:, 15, :3], landmarks[:, 16, :3]
    pos = (left_wr + right_wr) / 2.0  # ä¸¡æ‰‹ã®ä¸­ç‚¹
    y = pos[:, 1]
    z = pos[:, 2]

    # ğŸ¯ 1. æ‰‹ã®é«˜ã•å¤‰åŒ–ï¼ˆYè»¸ã®é€Ÿåº¦ï¼‰ã§ä¸Šæ˜‡â†’ä¸‹é™ã®è»¢æ›ç‚¹ã‚’æ¢ã™
    dy = np.gradient(y)
    dy_s = np.convolve(dy, np.ones(5)/5, mode='same')  # å¹³æ»‘åŒ–
    top_candidates = np.where((dy_s[:-1] > 0) & (dy_s[1:] <= 0))[0]  # ä¸Šæ˜‡â†’ä¸‹é™ã®å¤‰åŒ–ç‚¹

    if len(top_candidates) > 0:
        score = -y[top_candidates] + 0.3 * z[top_candidates]
        top_idx = int(top_candidates[np.argmax(score)])
    else:
        top_idx = int(np.argmin(y))

    # ğŸ¯ 2. ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆæ¤œå‡ºï¼šæ‰‹ã®ç§»å‹•é€Ÿåº¦ãŒæœ€å¤§ã«ãªã‚‹ç¬é–“
    vel = np.linalg.norm(np.diff(pos[:, :2], axis=0), axis=1) * fps
    vel_s = np.convolve(vel, np.ones(5)/5, mode='same')
    impact_idx = int(np.argmax(vel_s))

    # ğŸ¯ 3. ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆè£œæ­£
    impact_idx = max(top_idx + 1, impact_idx)
    impact_idx = min(impact_idx, T - 2)

    # =========================================================
    # ğŸ–¼ï¸ 4. æ¤œå‡ºã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”»åƒã¨ã—ã¦ä¿å­˜ï¼ˆvideo_pathãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
    # =========================================================
    if video_path is not None and os.path.exists(video_path):
        os.makedirs(output_dir, exist_ok=True)
        cap = cv2.VideoCapture(video_path)

        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        if top_idx < total_frames and impact_idx < total_frames:
            frame_indices = [top_idx, impact_idx]
            names = ["top_detect_frame.jpg", "impact_detect_frame.jpg"]
            for idx, name in zip(frame_indices, names):
                cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
                ret, frame = cap.read()
                if ret:
                    save_path = os.path.join(output_dir, name)
                    cv2.imwrite(save_path, frame)
                    print(f"ğŸ–¼ï¸ ä¿å­˜å®Œäº†: {name}ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ  {idx}ï¼‰")
        cap.release()
    else:
        print("âš ï¸ video_pathãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ç”»åƒä¿å­˜ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")

    return {"top": top_idx, "impact": impact_idx}

# =========================================================
# ğŸ§© ç‰¹å¾´é‡æŠ½å‡º
# =========================================================
def extract_summary_features(landmarks: np.ndarray, fps: int = 30, video_path: str = None, output_dir: str = "outputs") -> dict:
    T = landmarks.shape[0]
    kf = detect_keyframes(landmarks, fps, video_path, output_dir)
    top, impact = kf["top"], kf["impact"]

    # âœ… è¿½åŠ ï¼šãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã‚’å‡ºåŠ›
    print("========== ãƒ•ãƒ¬ãƒ¼ãƒ æ¤œå‡ºæƒ…å ± ==========")
    print(f"ğŸ“ æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·: 0")
    print(f"ğŸŒï¸ ãƒˆãƒƒãƒ—ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·: {top}")
    print(f"ğŸ’¥ ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·: {impact}")
    print(f"ğŸ æœ€å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·: {T - 1}")
    print("=====================================")

    def L(t, idx): return landmarks[t, idx, :2]

    shoulder_angle_top = line_angle(L(top, 11), L(top, 12))
    hip_angle_top = line_angle(L(top, 23), L(top, 24))
    x_factor = shoulder_angle_top - hip_angle_top

    left_elb = angle_3pt(L(impact, 11), L(impact, 13), L(impact, 15))
    right_elb = angle_3pt(L(impact, 12), L(impact, 14), L(impact, 16))
    elbow_at_impact = left_elb if abs(180 - left_elb) < abs(180 - right_elb) else right_elb

    t_back = max(1, top) / fps
    t_down = max(1, impact - top) / fps
    tempo_ratio = (t_back / t_down) if t_down > 0 else float('inf')

    nose_y_series = landmarks[:, 0, 1]
    head_std = float(np.std(nose_y_series))

    left_wr, right_wr = landmarks[:, 15, :2], landmarks[:, 16, :2]
    hand_pos = (left_wr + right_wr) / 2
    xs, ys = hand_pos[:, 0], hand_pos[:, 1]
    if np.ptp(xs) < 1e-6:
        hand_dev = 0.0
    else:
        p = np.polyfit(xs, ys, 1)
        hand_dev = float(np.mean(np.abs(ys - np.polyval(p, xs))))

    features = {
        "shoulder_angle_top": shoulder_angle_top,
        "hip_angle_top": hip_angle_top,
        "x_factor_top": x_factor,
        "elbow_at_impact": elbow_at_impact,
        "tempo_ratio": tempo_ratio,
        "head_std": head_std,
        "hand_path_dev": hand_dev,
        "top_frame": top,
        "impact_frame": impact,
        "frames": T
    }
    return features


# =========================================================
# ğŸŒï¸ è¿½åŠ : å‹•çš„ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³è§£æãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# =========================================================
def refine_impact_by_motion(landmarks: np.ndarray, fps: int, rough_idx: int, window: int = 3) -> int:
    """æ‰‹é¦–é€Ÿåº¦ï¼‹å‰è…•è§’é€Ÿåº¦ã‚’ç”¨ã„ã¦ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚’ç²¾å¯†è£œæ­£"""
    if landmarks.ndim != 3 or landmarks.shape[1] < 17:
        raise ValueError("landmarks é…åˆ—ãŒä¸æ­£ã§ã™ã€‚shape=(frames,33,3) å½¢å¼ã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚")

    left_wr, right_wr = landmarks[:, 15, :2], landmarks[:, 16, :2]
    pos = (left_wr + right_wr) / 2
    vel = np.linalg.norm(np.diff(pos, axis=0), axis=1) * fps
    vel = np.pad(vel, (1, 0), mode='edge')
    vel = smooth_series(vel, window=5)

    left_elb = landmarks[:, 13, :2]
    left_forearm = left_wr - left_elb
    ang = np.unwrap(np.arctan2(left_forearm[:, 1], left_forearm[:, 0]))
    ang_vel = np.abs(np.gradient(ang) * fps)
    ang_vel = smooth_series(ang_vel, window=5)

    score = 0.6 * vel + 0.4 * ang_vel
    start = max(1, rough_idx - window)
    end = min(len(score) - 1, rough_idx + window)
    refined_idx = start + np.argmax(score[start:end])
    return int(refined_idx)


def compute_hand_speed(landmarks: np.ndarray, fps: int) -> np.ndarray:
    """å„ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ‰‹é¦–é€Ÿåº¦"""
    left_wr, right_wr = landmarks[:, 15, :2], landmarks[:, 16, :2]
    pos = (left_wr + right_wr) / 2
    vel = np.linalg.norm(np.diff(pos, axis=0), axis=1) * fps
    vel = np.pad(vel, (1, 0), mode='edge')
    return smooth_series(vel, window=5)


def compute_arm_angular_velocity(landmarks: np.ndarray, fps: int) -> np.ndarray:
    """å·¦å‰è…•ã®è§’é€Ÿåº¦"""
    left_elb = landmarks[:, 13, :2]
    left_wr = landmarks[:, 15, :2]
    left_forearm = left_wr - left_elb
    ang = np.unwrap(np.arctan2(left_forearm[:, 1], left_forearm[:, 0]))
    ang_vel = np.abs(np.gradient(ang) * fps)
    return smooth_series(ang_vel, window=5)
